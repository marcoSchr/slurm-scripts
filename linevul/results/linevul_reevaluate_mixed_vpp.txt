slurmstepd: error: couldn't chdir to `/home/schroeder_e/slurm-scripts': No such file or directory: going to /tmp instead
slurmstepd: error: couldn't chdir to `/home/schroeder_e/slurm-scripts': No such file or directory: going to /tmp instead
Matplotlib created a temporary cache directory at /scratch/47615/matplotlib-9zyldo40 because the default path (/home/schroeder_e/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
12/19/2023 11:48:54 - WARNING - __main__ -   device: cuda, n_gpu: 1
Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at microsoft/codebert-base and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
12/19/2023 11:48:58 - INFO - __main__ -   Training/evaluation parameters Namespace(train_data_file='../data/vpp_dataset/train.csv', output_dir='./saved_models', model_type='roberta', block_size=512, eval_data_file='../data/vpp_dataset/val.csv', test_data_file='../data/vpp_dataset/test.csv', model_name='mixed.bin', model_name_or_path='microsoft/codebert-base', config_name='', use_non_pretrained_model=False, tokenizer_name='microsoft/codebert-base', code_length=256, do_train=False, do_eval=False, do_test=True, evaluate_during_training=False, do_local_explanation=False, reasoning_method=None, train_batch_size=4, eval_batch_size=256, gradient_accumulation_steps=1, learning_rate=5e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, max_steps=-1, warmup_steps=0, seed=42, epochs=1, effort_at_top_k=0.2, top_k_recall_by_lines=0.01, top_k_recall_by_pred_prob=0.2, do_sorting_by_line_scores=False, do_sorting_by_pred_prob=False, top_k_constant=10, num_attention_heads=12, write_raw_preds=False, use_word_level_tokenizer=False, use_non_pretrained_tokenizer=False, n_gpu=1, device=device(type='cuda'))
  0%|          | 0/2334 [00:00<?, ?it/s]  2%|▏         | 57/2334 [00:00<00:04, 567.47it/s]  5%|▍         | 114/2334 [00:00<00:04, 474.59it/s]  8%|▊         | 177/2334 [00:00<00:04, 531.70it/s] 10%|▉         | 232/2334 [00:00<00:07, 279.35it/s] 12%|█▏        | 283/2334 [00:00<00:06, 328.67it/s] 15%|█▍        | 350/2334 [00:00<00:04, 402.27it/s] 18%|█▊        | 419/2334 [00:01<00:04, 465.51it/s] 20%|██        | 474/2334 [00:01<00:04, 413.18it/s] 22%|██▏       | 523/2334 [00:01<00:04, 429.48it/s] 24%|██▍       | 571/2334 [00:01<00:04, 430.97it/s] 27%|██▋       | 634/2334 [00:01<00:03, 479.90it/s] 30%|███       | 702/2334 [00:01<00:03, 533.81it/s] 33%|███▎      | 760/2334 [00:01<00:02, 544.14it/s] 35%|███▌      | 817/2334 [00:01<00:02, 534.02it/s] 37%|███▋      | 873/2334 [00:01<00:02, 537.34it/s] 40%|███▉      | 928/2334 [00:02<00:02, 500.64it/s] 42%|████▏     | 983/2334 [00:02<00:02, 513.19it/s] 46%|████▌     | 1071/2334 [00:02<00:02, 613.72it/s] 49%|████▊     | 1137/2334 [00:02<00:01, 623.57it/s] 51%|█████▏    | 1201/2334 [00:02<00:02, 563.99it/s] 54%|█████▍    | 1260/2334 [00:02<00:01, 543.69it/s] 56%|█████▋    | 1316/2334 [00:02<00:01, 546.74it/s] 59%|█████▉    | 1372/2334 [00:02<00:02, 469.20it/s] 61%|██████    | 1428/2334 [00:02<00:01, 490.86it/s] 64%|██████▎   | 1483/2334 [00:03<00:01, 502.95it/s] 66%|██████▌   | 1540/2334 [00:03<00:01, 517.67it/s] 68%|██████▊   | 1593/2334 [00:03<00:01, 500.73it/s] 71%|███████   | 1660/2334 [00:03<00:01, 544.27it/s] 74%|███████▎  | 1716/2334 [00:03<00:01, 547.20it/s] 77%|███████▋  | 1804/2334 [00:03<00:00, 639.62it/s] 80%|████████  | 1869/2334 [00:03<00:00, 615.42it/s] 83%|████████▎ | 1932/2334 [00:03<00:00, 617.61it/s] 86%|████████▌ | 2002/2334 [00:03<00:00, 640.67it/s] 89%|████████▊ | 2067/2334 [00:04<00:00, 543.84it/s] 91%|█████████ | 2125/2334 [00:04<00:00, 536.75it/s] 94%|█████████▍| 2193/2334 [00:04<00:00, 556.97it/s] 96%|█████████▋| 2251/2334 [00:04<00:00, 527.28it/s] 99%|█████████▉| 2309/2334 [00:04<00:00, 539.50it/s]100%|██████████| 2334/2334 [00:04<00:00, 509.41it/s]
12/19/2023 11:49:12 - INFO - __main__ -   ***** Running Test *****
12/19/2023 11:49:12 - INFO - __main__ -     Num examples = 2334
12/19/2023 11:49:12 - INFO - __main__ -     Batch size = 256
12/19/2023 11:49:57 - INFO - __main__ -   ***** Test results *****
12/19/2023 11:49:57 - INFO - __main__ -     test_accuracy = 0.5
12/19/2023 11:49:57 - INFO - __main__ -     test_f1 = 0.6667
12/19/2023 11:49:57 - INFO - __main__ -     test_precision = 0.5
12/19/2023 11:49:57 - INFO - __main__ -     test_recall = 1.0
12/19/2023 11:49:57 - INFO - __main__ -     test_threshold = 0.5
